{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optional Graded assignment 5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWC0c6hEVxd6",
        "colab_type": "text"
      },
      "source": [
        "# a)Write  Colab for Seq2Seq pipeline using LSTM and using GRU for NMT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMIwsiW6QQsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxeDcSVeWNaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyJcZh9CWNkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJQJ899qWNm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj8CLO76WNpm",
        "colab_type": "code",
        "outputId": "04b07c4a-23cb-455c-a474-049a8cef9080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExdZ_CtoWNsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzW2AvsnWNuo",
        "colab_type": "code",
        "outputId": "fac30c17-6651-4d9d-c7b6-d88bb0aa415e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpqcbzBiWNxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPCJnPX-WNz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS1SgwOaWN2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TDbWNFxWN5S",
        "colab_type": "code",
        "outputId": "fa59fb06-c91b-48a9-e080-53bcd00d6eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFIa7Iobcf9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_tensor_train = input_tensor_train[:2400]\n",
        "# input_tensor_val = input_tensor_val[:2400]\n",
        "# target_tensor_train = target_tensor_train[:600]\n",
        "# target_tensor_val = target_tensor_val[:600]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNVc66lncx00",
        "colab_type": "code",
        "outputId": "3c467dd1-1c7a-46fe-829e-06f8a33ebcbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoXe_yywWN78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHkCqdeeXGSw",
        "colab_type": "code",
        "outputId": "9be1d051-9a0a-4421-fed2-832fc906ef84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "127 ----> tenemos\n",
            "219 ----> hambre\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "16 ----> we\n",
            "24 ----> are\n",
            "225 ----> hungry\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUOfmLLzXGVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onCTleZkXGYC",
        "colab_type": "code",
        "outputId": "95eef796-daeb-467a-ba00-b0d940d6f4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxN1Wm-5XGaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5_RUt4IXGdn",
        "colab_type": "code",
        "outputId": "96f393cf-b856-48ea-8f56-3ffdf858187c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hStcJ1peXGf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfruIGrxXGjB",
        "colab_type": "code",
        "outputId": "93301f11-3509-441a-f9b2-02594f03e262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-W_MwLbXGlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QIl79IGXGn9",
        "colab_type": "code",
        "outputId": "b711de49-f5b5-4559-b8be-3a65a354c198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlqFMTXxXGqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXtXphXJXGs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrLkxPuUXh96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5SPslMZXiAo",
        "colab_type": "code",
        "outputId": "2dd9226c-69dd-4bfc-81bb-703f9b1b051e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "#using just 5 epoch to avoid crashing\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7111\n",
            "Epoch 1 Batch 100 Loss 2.3818\n",
            "Epoch 1 Batch 200 Loss 1.7740\n",
            "Epoch 1 Batch 300 Loss 1.6739\n",
            "Epoch 1 Loss 2.0269\n",
            "Time taken for 1 epoch 83.4965660572052 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5431\n",
            "Epoch 2 Batch 100 Loss 1.5510\n",
            "Epoch 2 Batch 200 Loss 1.4278\n",
            "Epoch 2 Batch 300 Loss 1.3052\n",
            "Epoch 2 Loss 1.3872\n",
            "Time taken for 1 epoch 69.20318603515625 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1497\n",
            "Epoch 3 Batch 100 Loss 0.9657\n",
            "Epoch 3 Batch 200 Loss 1.0288\n",
            "Epoch 3 Batch 300 Loss 0.9644\n",
            "Epoch 3 Loss 0.9914\n",
            "Time taken for 1 epoch 68.06307983398438 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7402\n",
            "Epoch 4 Batch 100 Loss 0.6678\n",
            "Epoch 4 Batch 200 Loss 0.6040\n",
            "Epoch 4 Batch 300 Loss 0.6425\n",
            "Epoch 4 Loss 0.6736\n",
            "Time taken for 1 epoch 68.81752562522888 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4591\n",
            "Epoch 5 Batch 100 Loss 0.3955\n",
            "Epoch 5 Batch 200 Loss 0.4474\n",
            "Epoch 5 Batch 300 Loss 0.5664\n",
            "Epoch 5 Loss 0.4515\n",
            "Time taken for 1 epoch 68.08899283409119 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K6Vr_2JX4EQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxp020loXiDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYthG9tRXiFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM1wJnWnXiIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umN3Nn2ZXiLK",
        "colab_type": "code",
        "outputId": "42448355-680a-4e15-8d12-3358884b6483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcebb1679e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0-IndBNXiNj",
        "colab_type": "code",
        "outputId": "c2d34b98-a91d-4aed-fb5c-bc5125ce9c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s a cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAJwCAYAAAC08grWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5itB1nf/d+d7BxMAiIHIaDIWQ4CIWyBAEosVixY3+qrIgKC9iUo8AKKtaWUQmkB0aCgoCXWgggoilBEWijHBkSMgAgpxxhOESFEAiQkBMi++8ezNswMe4eEJnOvPfP5XNe+rjXPWjNzz5Odvb7zHKu7AwAw4bDpAQCA3UuIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhMgaqKqbV9Xrq+q207MAwHYSIuvhQUlOTvKzw3MAwLYqN72bVVWV5MNJXpPknye5fndfOjoUAGwTW0TmnZzkakkemeTLSe49Og0AbCMhMu9BSV7S3Rcl+aPVxwCwK9g1M6iqjk3yD0nu091vqqoTkvxlkuO7+zOz0wHAVc8WkVn/b5LzuvtNSdLd70zywSQ/OToVAIe8qjq2qn66qr55epbLIkRmPTDJC7Yse0GSB2//KADsMD+R5LlZ3mvWll0zQ6rq25N8KMmtuvuDG5Z/W5azaG7d3R8YGo81UFW3S/JLSW6dpJO8J8mvdfeZo4MBh4SqekOS6ya5qLv3Ts9zMEIE1lBV/XCSlyZ5U5I3rxbfffXnR7v7FVOzAeuvqm6U5ANJ7pTkrUlO7O73TM50MEJkUFXdMMnH+gD/Earqht390YGxWANV9a4kL+vuJ2xZ/qQk/093335mMuBQUFWPT3Jyd9+zql6a5IPd/a+n5zoQx4jM+lCS62xdWFXXWj3H7nWLJH9wgOV/kOQ7t3kW4NDz0/nqvyEvTHL/1QU0144QmVVZ9v1vdVySL2zzLKyXc5Pc8QDL75jkk9s8C3AIqaq7Jjk+yUtWi16R5Jgk3z821GXYMz3AblRVv7l62EmeWlUXbXj68Cz79N657YOxTn43yXOq6mZJ3rJadrcsB6/+2thUwKHgQUle3t0XJkl3f7Gq/jjLGZmvmRzsQBwjMmB1JHOS3CPLBcy+uOHpL2Y5a+bUjWfTsLusNqE+Osljklx/tfjjWSLkNw90XBFAVR2V5BNJ7tfdr9qw/O5JXp3kuvsDZV0IkSGrN5o/TvKz3X3B9Dysr6q6WpL4ewJ8PVV17Sz3LHtBd+/b8twDkry2uz8xMtxBCJEhVXV4luNAbr+up1QBwFXNMSJDuvvSqvpIkiOnZ2H9VNU1kzw5yT2TfGu2HFje3VefmAvgyiZEZv3HJL9SVQ/o7vOmh2Gt/F6SOyQ5LcuxITZdAgdVVR/K5fx3ortvchWPc4XYNTOoqt6d5MZJjkhyTpLPb3y+u283MRfzqupzSf5pd//V9CzA+quqx2z48Lgkv5jkjCwnRCTJSVnOyHx6dz9pm8e7TLaIzHrJ138Ju9S5SdbqyHZgfXX30/c/rqrnJXladz9l42uq6rFJbrPNo31dtojAGqqq+2a5c+aD1u1UO2C9rbaontjdZ21ZfrMk71i3Y8xsEWFtVNXDkjw8y+6q7+rus6vq3yQ5u7v/eHa6q95qV93G3wxunOTc1UHNX9r4WrvtgMvw+SQnJzlry/KTk1y09cXThMigqjoyyeOS3C/JDbMcK/IV3X34xFwTqurRSX45ydOS/MqGp/4+ySOyXHNlp7OrDrgy/EaSZ1fV3ix33k2Su2S54uoTp4Y6GLtmBlXV05LcN8lTs/zF+XdJbpTkJ5M8vrufMzfd9qqq9yV5THe/sqouyHJ9lbOr6jZJTu/uaw2PCKOq6sQk7+zufavHB9Xd79imsVhTVfUTSR6V5FarRe9N8sx13LosRAatTrf6+e5+1erN94Tu/ruq+vkk9+zuHxsecdtU1cVJbtndH9kSIrfI8o/vMcMjbququkeSdPf/OsDy7u7TRwZjTFXtS3K97j539biz3Dhzq95NW1M59Nk1M+u6SfZfVfXCJNdYPX5Vll0Uu8nZSU5M8pEty++dr66j3eQ3khzoFLurZ9m0eqA787Kz3TjJpzY8hq+rqq6Rr70g4qeHxjkgITLro1luaPbRLAcV3SvJ27Oc733x4FwTTk3yrKo6JstveSdV1QOzHDfys6OTzfjOJH97gOVnrp5jl+nujxzoMWxVVd+R5D9nOTh149W7K8uWtLXaYiZEZr0syyW835rkmUn+sKoekuQG2WW3eu/u51bVniRPSXJMkj/IckXRR3b3i0eHm3FxkuOTfGjL8htk892a2YUcI8LX8dwsW9j/ZQ6BKzM7RmSNVNWdk9wtyQe6+8+n55myunvkYd197vQsU6rqhVnOpPrh7j5/teyaSV6e5Jzuvt/kfMw6yDEiX/nH3DEiu1tVXZjkLt195vQsl4cQGVRV35vkLd395S3L9yS56246IHF1dszh3f2uLctvl+TLu+0OxVV1fJLTs9zwbv86uV2WK67eo7s/PjUb81ab3jc6Isu9iR6X5LHd/T+2fyrWxeqaRA/u7rdPz3J5CJFBVXVpkuO3/uZfVddKcu5u+q2mqv4iybO7+0Vblv9kkkd0991nJpuzOl7m/klOWC36myQv6u61uyDRdqiqf5Lk1ll+839Pd79heKS1U1U/kOQJ3X236VmYs/p/5d8kedjWq6uuIyEyaLV59brd/akty2+R5G3rdhneq9LqlN07HOCSxDfNcknib56ZjGlVdYMsx1PdMcv+7mQ5yPttSX7E1qGvqqqbZznd/djpWZiz+vf0qCwHpV6SZNNW93V7b3Gw6oCq+rPVw07ygqq6ZMPThyf5riRv2fbBZl2a5ECx8S058LUSdrSq+tHLer67X7pds6yB38zy9+Nm3f2hJKmqmyR5weq5XXO9nf1WxwttWpTl4OYnJnn/tg/EunnE9ABXhC0iA6rquauHD8py6fKNp+p+McmHk/xud5+3zaONqaqXZ3mz+fHuvnS1bE+SP0lyRHf/0OR82221texAOtldByOubuB18tYzQVaXr37dbtxatuFg1U2Lk3wsyX27+61f+1mwnmwRGdDdP5MkVfXhJKd29+dnJ1oLv5zkzUnOqqo3r5bdPclxSb53bKoh3b3pAkSrKLtDltO6Hzcy1KwD/ca0m3+L+r4tH+/LcrGzs7Ye/M7uVFXXTfLAJDfNcsuQ86rqbkk+vn/L4rqwRWRQVR2WJN29b/Xx9ZL8UJYD8Xbbrpn9Z4o8IpsPzvxtxwB8VVXdNcnvdPftp2fZLlX1siTXSXK/7v7YatkNk7wwyae6+zJ3Y8FuU1V3TPK6LNchuk2W22ecXVVPTHKL7v6pyfm2EiKDqup/JHlVdz+zqo5L8r4kx2bZCvAvu/v5owOydqrq1knO6O7jpmfZLlX17Un+LMuxUxsPVn13luusnDM125TVqf+Xy266DACLqnpDlpuFPmHLvbtOSvJH3b319O9Rds3M2ptll0SS/GiSz2W5h8T9k/xSkl0XIlV1/SwX8tp4WeJd94/pAa6cuf9gxH+dZUvRrtHdH1utj+9PcsvV4vd292sHx5r2xnx119T+g7m3frx/2a45noivuGOWq6pu9Q9Z7nG2VoTIrOOSfGb1+AeSvKy7v1RVr0/y7Lmxtt8qQF6U5XiQ/VeM3Li5brf9Y/q2HPjuqm/NLrz3Ti+bbl+z+sOyC/fUJE9O8perZScl+bdZfrlxsOrudnGWMw63umWWiyKuFSEy66NJ7lZVr8hyw7sfXy2/ZpLddtGqZ2Q5a+bWSf46yQ9mKfcnJfmFwbmmbL276r4sx0N8YWKY7VZVv5jl+KAvrB4fVHf/+jaNtU7+Y5JHdffGMDu7qs5N8qvdfYehuVgPL0/yhKra/57SVXWjLHd1/9OpoQ7GMSKDquqhSZ6V5MIkH0lyYnfvq6pHJvkX3f1PRgfcRlX1yST36e63rU7X3NvdH6iq+2Q54vsuwyNuu9VR73fLcpn3rbfx/u2RobZJVX0oy9+Bf1w9Ppju7pts11zroqouzvLvxXu3LL91krd39zfNTMY6qKqrJ/nvWW4LcWyST2T5xe4tSf7Zup2pKUSGrY5uvmGS13T3hatl90nyme7+i9HhttEqPm7X3R9endb8gO5+c1XdOMn/7u5jZifcXlX1gCT/JcuumfOzeTdVd/f1RwZjLVTV25KcleRnuvvi1bJvynLX1Zt1997J+VgPq0u9n5jlF5l3rOtxVXbNDKmqb87yxvumJFtvTPSZJLvqJm9Zzhi6ZZaLub0zyc9V1ceSPDzJ3w/ONeXJSX41yZN283UhquqILNeX+enudsXQr/r5JH+e5O+rav9NEW+bZffmfcamYtzG95bufn2S12947m5ZLg9x/tiAB2CLyJCqulqWI5jvtXHLR1XdPskZSW6wy66sev8sV1B93uoMiVcluXaW+yQ8qLv/eHTAbVZV5ye5Y3efPT3LtNVxD3fv7g9Mz7JOqurYJD+V5FarRe/NclPEtdrszvY6FN9bhMigqnphkgu7+6Eblp2a5YIzPzw32bzVnWdvmeSj6/Y/zXaoqmcleX93/9b0LNOq6teSpLv/1fQs62R1td075cCnu++6U//5qkPtvUWIDKqqeyX5wyTX6+4vrq60ek6W297vppuaJUmq6r5J7pkDH5y5dv/zXJWq6sgk/y3LvYfeneRLG5/v7idNzDWhqn47y7V1PpRlN+am3/i7+5ETc02qqlsmeUWWs6sqyy6ZPVn+nlyybndXZXsdau8tjhGZ9Zos53v/UJKXZnkTPjLLPzC7yuq33kcneUOWq2fu9kJ+aJZTmM9LcrNsOVg1y2nNO9bqyqFvWR0fc6sk+294t/UMmd369+QZWaLshCxnRJyQ5e7Vv5Pk3w3OxXo4pN5bbBEZVlVPS/Kd3f0vqur5SS7o7odPz7XdVqfvPry7XzI9yzpYHRfx1O7+jelZJlTVpUmO7+5zq+rsJN/d3f84Pde6qKp/THKP7j6zqj6b5E7d/f6qukeS3+ru2w2PyLBD6b3FFpF5z0/y9tVNvH4kS7nuRodlOVuGxeFZ7q+yW52fZbfDuUlulC276kjlqxc9/FSSGyR5f5bN7zebGoq1csi8t9gisgZW1wS4OMm1u/tWX+/1O1FVPTnJl7r7idOzrIPVgWWf203HgmxUVc9J8qAsR//fMMsb7KUHeu0uvaDZ6Ul+o7tfVlUvSnKtJE9J8pAsp27aIsIh895ii8h6eH6Wfb6Pmx5kO1XVb2748LAk96+qf5rkXfnagzN32wGJxyT5/1YHne3G9fFzWbYI3TzJr2e5UNcFoxOtlydnuWJmshwT8sosx1edl+QnpoZaN1X13iQ37+7d+l53SLy37Nb/OOvmBVluUPTc6UG22W23fLx/18wttyzfjZvtbpWv3mV3162P1U3uXpl85foHT+9uIbLS3a/e8PjsJLeqqmsmOb9t5t7o2Vm2Fu1Wh8R7i10zAMAYB4ABAGOECAAwRoisiao6ZXqGdWJ9bGZ9bGZ9bGZ9bGZ9bLbu60OIrI+1/osywPrYzPrYzPrYzPrYzPrYbK3XhxABAMbs+rNmjqyj+uivnI4/50u5JEfkqOkx1ob1sZn1sZn1sZn1sZn1sdm6rI8Lcv553X2drct3/XVEjs6xuXOt7ZVvAWBHeG2/5CMHWm7XDAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwZkeESFU9r6r+fHoOAOCK2TM9wJXkUUkqSarqjUnO7O5HjE4EAHxdOyJEuvuz0zMAAFfcjgiRqnpekmsnOS/JPZLco6oevnr6xt394aHRAIDLsCNCZINHJblFkvcl+berZZ+aGwcAuCw7KkS6+7NV9cUkF3X3Jw72uqo6JckpSXJ0jtmu8QCALXbEWTNXVHef1t17u3vvETlqehwA2LV2ZYgAAOthJ4bIF5McPj0EAPD17cQQ+XCSO1XVjarq2lW1E39GANgRduKb9KlZtoq8J8sZMzecHQcAOJgdcdZMdz94w+MPJDlpbhoA4PLaiVtEAIBDhBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMbsmR5gWh2xJ3uufd3pMdbG2T930+kR1sqRJ5w/PcJauf4Dz5keYa3s+/xF0yOsl32XTk/AIcgWEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMbsuBCpqu+tqrdW1YVV9dmqOqOqvmt6LgDga+2ZHuDKVFV7krw8ye8luX+SI5KcmOTSybkAgAPbUSGS5OpJrpHkFd39d6tl79v6oqo6JckpSXL04cdt33QAwCY7atdMd386yfOSvLqqXllVv1hVNzzA607r7r3dvffIw75p2+cEABY7KkSSpLt/Jsmdk5ye5IeTvL+q7jU7FQBwIDsuRJKku/+2u5/W3ScneWOSB81OBAAcyI4Kkaq6cVX9SlXdtaq+o6q+L8ntkrxnejYA4GvttINVL0pyiyR/kuTaST6Z5IVJnjY5FABwYDsqRLr7k0l+dHoOAODy2VG7ZgCAQ4sQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDG7JkeYNyl+7Lvggunp1gbN3neOdMjrJWT/uwD0yOsldfd7XumR1grR//F+6ZHWCv7Pn/R9AjrZd+l0xMcEmwRAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYMyOCZGq+sGqelNVnV9Vn66qV1fVrabnAgAObseESJJjkzwjyZ2SnJzks0leUVVHTg4FABzcnukBrizd/acbP66qn0nyuSxh8uYtz52S5JQkObqO3a4RAYAtdswWkaq6aVW9qKr+rqo+l+STWX6+G259bXef1t17u3vvkXX0ts8KACx2zBaRJH+e5JwkD03y90m+nOQ9SeyaAYA1tSNCpKquleSWSR7W3W9YLTsxO+TnA4Cdaqe8UZ+f5LwkD6mqjyW5QZJfy7JVBABYUzviGJHu3pfkvklul+TMJM9O8vgkl0zOBQBctp2yRSTd/fok37Vl8XETswAAl8+O2CICAByahAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMGbP9ABr4TA9tt+XP/zR6RHWylvucfz0CGvlEX/14ukR1sqzH/bj0yOslaPfdtb0CGvl0s98dnqEQ4J3YABgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgzCEZIlX1xKo68+u85llV9cZtGgkA+AYckiECAOwMQgQAGDMWIrV4TFV9sKouqapzquqpq+duW1WvraqLq+rTVfW8qvrmy/hah1fVqVV1/urPM5Icvm0/DADwDZncIvKUJI9P8tQkt0ny40k+VlXHJnl1kguT3CnJjyS5a5L/ehlf6zFJHpLkoUlOyhIh97/KJgcArhR7Jr5pVR2X5BeSPLq79wfGWUn+sqoekuTYJA/s7gtWrz8lyRuq6mbdfdYBvuSjk/xqd//x6vWPSnKvy/j+pyQ5JUmOrmOvpJ8KALiipraI3DrJUUled4DnbpXkXfsjZOUtSfatPm+T1S6b45P85f5l3b0vyV8d7Jt392ndvbe79x5ZR39jPwEA8H/tUDtYtacHAACuPFMh8t4klyS550Geu21VXW3DsrtmmfW9W1/c3Z9N8g9J7rJ/WVVVluNLAIA1NnKMSHdfUFXPTPLUqrokyelJrpXkjkl+P8l/SPL8qvr3Sb4lyXOSvPQgx4ckyTOTPLaqPpDk3UkelmV3zT9ctT8JAPB/YyREVh6b5PwsZ858W5JPJnl+d19UVfdK8owkZyT5QpKXJ3nUZXytpye5XpL/svr4D5K8MMvxJgDAmhoLkdUBpb+y+rP1uXfnwLtt9j//xCRP3PDxl7OchfMLV/acAMBV51A7WBUA2EGECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwZs/0ANN6377su+CC6TFYU5eef/70CGvltFvcZHqEtXJE3j49wlq59LDDp0dYL9bHZpceeLEtIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAmG0Nkap6Y1U9azu/JwCwvmwRAQDGHPIhUlVHTM8AAHxjJkLksKp6SlWdV1XnVtWpVXVYklTVkVX1tKo6p6ouqqq/rqp77f/Eqjq5qrqq7l1VZ1TVF5Pcqxa/XFV/V1UXV9W7q+oBAz8bAHAF7Bn4nvdP8swkd01yQpIXJXl7kj9M8twkN03yU0nOSXLvJK+oqu/u7r/d8DWeluQxSc5KckGS/5Tkx5I8PMn7k5yU5Her6vzufuXWAarqlCSnJMnROeYq+BEBgMujunv7vlnVG5Mc1d0nbVj2miQfSfLUJB9McqPu/uiG5/9bko9398Oq6uQkb0jyY939p6vnj01yXpIf6O43bfi8ZyS5RXff+7Jmunpds+9c97ySfkKAXeyww6cnYI299tIXv727925dPrFF5F1bPv54km9NcmKSSvKeqtr4/FFJXr/lc9624fGtkxyd5FVVtbGqjkjy4SthXgDgKjIRIl/a8nFnOVblsNXj7z7Aay7e8vHnNzzef5zLP0/y0S2v2/p1AIA1MhEiB/M3WbaIXK+733AFPu89SS5J8h3dvXXLCQCwxtYmRLr7A1X1wiTPq6rHJHlHkmsmOTnJ2d390oN83gVVdWqSU2vZp3N6kuOS3CXJvu4+bVt+AADgClubEFn5mSSPS/KrSb4tyaeTnJHlANXL8vgkn0zyS0l+J8nnkrxz9XUAgDW1rWfNrCNnzQBcSZw1w2U42Fkzh/yVVQGAQ5cQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDG7JkeADiEHHb49ARr5fCb33h6hLVy4ovfPz3CWnnz4+4yPcJ6+fMXH3CxLSIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwJg90wNMqKpTkpySJEfnmOFpAGD32pVbRLr7tO7e2917j8hR0+MAwK61K0MEAFgPQgQAGCNEAIAxOzZEquoRVfW+6TkAgIPbsSGS5NpJvnN6CADg4HZsiHT3E7u7pucAAA5ux4YIALD+hAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMGbP9ADAIWTfpdMTrJVL33/W9Ahr5YyHnTg9wlp540t+d3qEtXL48QdebosIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADDmkAmRqvqlqvrw9BwAwJXnkAkRAGDnuVJCpKquXlXXuDK+1hX4ntepqqO383sCAFeubzhEqurwqrpXVb0oySeS3H61/Jur6rSqOreqLqiq/1VVezd83oOr6sKqumdVnVlVn6+qN1TVjbd8/V+uqk+sXvv8JMdtGeHeST6x+l53+0Z/DgBgzhUOkaq6TVX9apKPJXlxks8n+cEkp1dVJXllkhsk+aEkd0hyepLXV9XxG77MUUkem8hGq18AAAUDSURBVORnk5yU5BpJ/vOG7/ETSf5TkickOTHJ+5P84pZRXpjkp5JcLclrquqsqvr3W4PmID/DKVX1tqp625dyyRVdBQDAleRyhUhVXauqHllVb0/yN0lumeRRSa7X3Q/p7tO7u5N8X5ITkvxYd5/R3Wd19+OTnJ3kgRu+5J4kD1+95l1JTk1y8ipkkuTRSX6/u5/T3R/o7icnOWPjTN395e7+7919vyTXS/KU1ff/YFW9sap+tqq2bkXZ/7mndffe7t57RI66PKsAALgKXN4tIv9/kmcm+UKSW3T3D3f3n3T3F7a87o5JjknyqdUulQur6sIk35Xkphted0l3v3/Dxx9PcmSSb1l9fKskf7nla2/9+Cu6+3Pd/V+7+/uSfHeS6yb5vSQ/djl/PgBgwJ7L+brTknwpyU8nObOqXpbkD5K8rrsv3fC6w5J8Msn3HOBrfG7D4y9vea43fP4VVlVHZdkV9IAsx4787yxbVV7+jXw9AGB7XK43/u7+eHc/ubu/M8n3J7kwyR8lOaeqnl5VJ6xe+o4sWyP2rXbLbPxz7hWY671J7rJl2aaPa3H3qnpOloNlfyvJWUnu2N0ndvczu/v8K/A9AYBtdoW3QHT3W7v755Mcn2WXzS2S/HVVfU+S1yb5iyQvr6p/VlU3rqqTquo/rJ6/vJ6Z5EFV9ZCqunlVPTbJnbe85gFJ/meSqye5X5Jv7+5/1d1nXtGfCQCYcXl3zXyN7r4kyUuSvKSqvjXJpd3dVXXvLGe8/G6Sb82yq+Yvkjz/CnztF1fVTZI8OcsxJ3+W5NeTPHjDy16X5WDZz33tVwAADgW1nOyye129rtl3rntOjwFwyOu73n56hLXyP1/y+9MjrJXDjz/r7d29d+tyl3gHAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgzJ7pAQDYGeotfzs9wlq51/VPmB5hzZx1wKW2iAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY/ZMDzChqk5JckqSHJ1jhqcBgN1rV24R6e7Tuntvd+89IkdNjwMAu9auDBEAYD0IEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgTHX39AyjqupTST4yPUeSayc5b3qINWJ9bGZ9bGZ9bGZ9bGZ9bLYu6+M7uvs6Wxfu+hBZF1X1tu7eOz3HurA+NrM+NrM+NrM+NrM+Nlv39WHXDAAwRogAAGOEyPo4bXqANWN9bGZ9bGZ9bGZ9bGZ9bLbW68MxIgDAGFtEAIAxQgQAGCNEAIAxQgQAGCNEAIAx/wfHB8oX7E5DcwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky7_wWGQXGvd",
        "colab_type": "code",
        "outputId": "f4a0301c-4932-4d54-ddb0-a1cf0130c5c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "translate(u'esta es mi vida.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NesECwmBXGx1",
        "colab_type": "code",
        "outputId": "9c312678-fa4d-4724-d14e-8c19c74d4ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "translate(u'¿todavia estan en casa?')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: are you still at home ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJwCAYAAAAjo60MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZhldX3n8c8XmkUgLqAiLuAW467RjrhEB0MUzeKMy2hcQSNEcXfUxCRGo1EnbiMuGcV932PUGNeo4xIdg0Yj4oZLUAkiboiy850/zu2hquzWbuiu86uu1+t56ul7z71V/a3zQNW7z1rdHQAA5rfL3AMAADARZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgOoql+vqg9V1Q3mngUAmI8wG8PhSQ5J8oCZ5wAAZlRuYj6vqqok30rygSR/mOSK3X3+rEMxjKq6QpLdly7r7pNmGgeAHcwWs/kdkuTXkjw8yXlJfm/WaZhdVV2qql5VVWcm+W6Sb674AGAnJczmd3iSt3b3z5O8cfGc9e1ZSW6U5L8lOSvJvZI8Nsl3ktxjxrkA2MHsypxRVe2d5D+T/H53f6yqbpzkk0kO6O4fzzsdc6mq7yS55+K/idOT3KS7T6yqeyZ5QHffbuYRAdhBbDGb112TnNbdH0uS7v5ckq8l+aNZp2Jul07yH4vHP0my3+LxJ5PccpaJANa4qtq7qu5XVZeae5ZfRpjN675JXrti2WuTHLH6ozCQrye5+uLxl5L80eIkkbsk+eFsUwGsbXdP8opMv3uHZVfmTKrqKpkO5L5Od39tyfIrZzpL87rd/dWZxmNGVfWoJOd39/Oq6neS/GOS3TL9Q+oR3f2CWQcEWIOq6sNJ9k/y8+7eOPc8WyLMYHBVdWCSjUm+1t1fmHsegLWmqq6a5KtJbpbkU5mO3T1hzpm2xK7MGVXVgYtdVJt9bbXnYUzdfVJ3/70oA7jI7pvkY4tjuf8pA18BwRazGVXV+ZnOwDx1xfL9kpza3bvOMxmrraoeneTvuvusxeMt6u7nrNJYADuFqvpakqd29yur6q5JjklylR4wgoTZjKrqgiT7d/f3Vyw/KMkJ3b33PJOx2qrqm0k2dvcPFo+3pLv76r/kdQCWqKpbJnl/kit09xlVtXuSU5Lco7s/MO90v2jD3AOsR1X1vMXDTvL0qvr5kpd3zbQP/HOrPhiz6e6rbe4xABfb4Une0d1nJEl3n1NVb850BQRhRpLkBos/K8l1kpyz5LVzknw209XfWYeq6saL4yAAuBiqao9Ml8m454qXXpvkfVW1z6ZgG4VdmTNZHPT/5kxXcv/p3PMwjsUu7hOSvCbJ67v72zOPBLAmVdVlM92D+rXdfcGK1+6T5IPdfcosw22BMJtJVe2a6T6INxr1lF3mUVXXSnLvTP/Cu3qSj2eKtLd290/mnG0uVbVnkkckOTTJ5bPijPLuvuEccwFsb8JsRlV1YpK72W3FllTVwZki7e5JLpnk3d393+edavVV1cuT3DnJW5KcnOn4zP+vu/96jrkAtjdhNqOqOjzTVpH7dPdpc8/DuBaB9qIkN1yPl1Gpqh8muXt3f3DuWYDxLc5u36rAGe1Mdwf/z+sxSa6W5LtV9Z0kP1v6ot0z61tVXS3T1rJ7J7lmko8meeCsQ83n50kcawdsraW3rtsnyaOTfDrJJxfLbpHpCgjPXuW5fiVbzGZUVU/8Za/bPbM+VdVDMsXYwUmOz3T20Ou7+7uzDjajqnp4kusledCIF4QExlVVr0zy1e5+2orlj09yve6+zyyDbYEwg8FU1UlJ3pDpLCK3YUpSVe9KcuskP8l0xuq5S1/v7jvNMRcwvqo6PdO9MU9csfyaST7b3ZecZ7LNsysTxnOQrUK/4LQkb597CGBN+lmSQ5KcuGL5IZkOkxiKMJvR4rYQf5HpBIADk+y29PX1eJA30z2XkqSqrpjpv4vdV7z+0TnmmlN333/uGRiXn6X8Cv8ryQuramOSTy2W3TzTHQGeNNdQWyLM5vWUJPdI8vRM/+E8NslVk/xRkifMNxZzWgTZGzLtuutMd4hYugXNLxlYzs9Stqi7n1FV38p0LcS7LxZ/Kcnh3f3m2QbbAseYzWhxOu+Du/u9VfXTJDfu7q9X1YOTHNrdd5t5RGawuIfbfkkekuRfk9whyf5JnpzkUSPedHc1VNX9c+EWkZVbEYc63Z3V5WcpO5NdfvVb2IH2z3Qgc5KckeTSi8fvTXL7WSZiBP8lyZ9295czbSn7fnf/fZI/zbRlYN2pqsdmOq39M5m2hPxDpjNW903y8vkmYxB+lrJVqurSVbXv0o+5Z1pJmM3rpCRXXDw+Mclhi8e3SHLmLBMxgktkOtg9SX6Y6RZEyfSLZ71e2+7IJEd19+MznZH5gsWZmM9OctCskzECP0vZoqo6qKreU1VnJvlBku8vPk5b/DkUx5jN6+2Z7v33qSTHJHlDVR2Z5EpJnjnnYMzqy0muneRbST6X5EFV9e1MuzbX67XMrpzp4pDJ9It20+ntb1gsP3KOoRiGn6X8Mq/ItBX1j7OZW7qNxjFmA1ncdudWmS6E949zz8M8qureSXbr7ldW1U0y7Y7ZL8nZmQ5WfcusA86gqr6R6b6yn62qf03y8u7+31V1hySv6+79Zh6RgVTVzZPcMn6WkqSqzkhy8+4+fu5ZtoYwm1FV3SbJv3T3eSuWb0hyy/V4WQR+UVXtlWkL2knr9Z6qVfXSJN/p7idV1YMynXn3qSQ3SfLm7rbFDNisqvpCkiO6+zNzz7I1hNmMqur8JAd096krlu+X5FTX3oFJVe2SZJdN/4ipqntksXU5yYu7+9xf9vns3Krq7kl+3N3vXzz/qyRHJflipl/I/znnfMyrqn4nyZ8lOXrl1f9HJMxmVFUXJNm/u7+/Yvm1khw32m0i2HGqaqvPLOzuB+zIWUZUVQcm+fbKOyJUVSW5SnefNM9kjKCqTkjyyO5+/2L3/78k+atMl5o5pbvvNeuAzGpxCZU9Ml0D8uwky/ZSjfa71sH/M6iqdy4edpLXVtXZS17eNcn1M/1gYf243Irnt0lyQZJN98q8fqazqNfr7u1vJjkgyakrlu+7eM3W5fXtoCRfWTy+c5J/WFxU9P1J3jffWAzioXMPsC2E2Tx+sPizkvwoy0/nPifJx5O8ZLWHYj7d/YebHlfV4zP9N3H/7v7ZYtneSV6WC0NtvVl594NN9kly1irPwnjOSvJri8eH5sJr2/1kyXLWqe5+1dwzbAu7MmdUVU9M8qxNv3whSarqPzNdrfyEFcuvl+Sfu/sK80y2+qrqeYuHD8l0yvvSGw7vmuRmSc7p7lut9myMo6r+IdP1/z6e6RZMV+3uk6vqsCTP6+7fmHVAZldV+ye5b5JrJHlCd59WVbdKcnJ3f3Pe6ZZzgdl5PSVLtpZV1RWq6oFVdcsZZ2J+++TCi2UudUCSvVZ5lrndYPFRSa6z5PkNklwzyWeTHDHXcAzjoZn2NtwtyYO6++TF8jvGrsx1r6pummlX970zXcts0zFlt0vy1Lnm2hJbzGZUVe9J8t7uPqaq9sl0YdG9M/1i/uPufvWsAzKLqnplpt0xj810SYgkuXmSv03y4e4+Yp7J5lNVr0jyiO4+fe5ZRrG4jMqNM90ZYtk/she38AKSVNWHk3y0u5+4OBHgRt39jaq6RZI3dvdQdw8RZjOqqu8n+Z3u/kJV3S/T6bw3ylT1j+7u9Xr7nXWtqi6R6VZDD0iy22LxeZmOMXtMd/98S5+7XizW0a2SfK27/2PueVZbVf1uprsebO7Cuu1SO3Chqjo9043tv7EizK6a5MvdveesA65gV+a89kny48Xj2yd5++J6TB/KtB+cdai7z+zuozP90v3Nxce+3X30eo2yqnplVR29eLx7ptswvT/JV6rqjrMON49jkrw7yZW7e5cVH+suyqpq96r666r6alWdVVXnL/2Yez5md2aSy2xm+bXzi2d6z06YzeukJLdanHF3WJIPLJbvm+UHObM+nZ/pkhnnLz7Ws8Ny4W7dO2U60+4KSZ60+FhvrprkKUuOpVrvnpLk8Exbmi/IdBjACzOdAX/0jHMxhnckeWJV7bF43outZX+b5G1zDbUlwmxez0nymiTfyXRz6k3XqLpN1u9lEda9qtpQVc/MdCmVz2f6b+FHVfWMqtrtl3/2TusyufBftndI8rbFHTPemOS6s001n08kcabhhe6e6aD/F2f6R8w7uvvhSZ6Y6QBv1rfHZNrg8f1MJ1B9PMmJmS6n8pczzrVZrmM2o+5+cVUdl+TAJB/o7gsWL3090ynfrE/PSHLPJA/K9AMkSW6d5OmZ/jH1mJnmmtMpSa6/uJTIYZlut5NMhwOsx9sxvSjJs6rqipnCfdk66O7PzjLVfPZPsunyMmckufTi8XszbRVhHVucNPTbi1sz3STTz9HPdvcH551s84TZTKrqUklu2N0fS7Lyxqo/zoU/ZFh/7pXkAd39T0uWfX1xsshLsz7D7OVJ3pTk5ExbRP55sfzgTGczrzdvXfx57GZe66y/OyGclOkSMydl2hJyWKafq7fI8gt4s84s/V3b3R/KdAz3ptduleSE7v7RbANuhjCbzwVJ3lNVh3X3JzYtrKobZfoP50qzTcbcLpVpq+lKX8+FWwLWle5+clUdn+nWO2/u7nMWL52X9blF5GpzDzCYt2e6xMynMp0Y8YaqOjLTz9FnzjkYs1tzv2sdYzaT7v5ppgMS77fipfsmeV93n7b6UzGIzyd5+GaWPyLJ51Z5lpGcmeR3k3ygqq6yWLZ7pl1X68riEiHXzXSA+3uSXLBYdrtMF95dV7r78d391MXjtyb57STPT3KX7v6LWYdjVmvxd60wm9erk/z3xen/qapdMu3GeuWcQzG7xyU5vKq+UlWvWnx8Jcl9Mp1ttu5U1b2TvDnJVzNtLdp0EsQumdbXurJkfXwty9fHrlmf6+OpVfWgTc+7+/9293OSXLmqnjLjaIxhTf2uFWbz+kCmrQB/sHh+aKYtAO+abaJBVdWuVfWQqloPu3C+leRamY4j2mfx8ZZMZ+GdNN9Ys3pckiO7+1GZdl9u8qlMV79fb6yP5e6b5N82s/wz+cUtJTu1qvqDqnpkVa2be+puhTX1u1aYzWhxFuZrc+EPjvsmedPiIrMs0d3nJ7l+kifPPcsq+GaS87r7L7r7rouPv0xy9uK19ejXk3xyM8vPyIX3vVtPrI/lLp/pUggr/SDTGZvrQlX9Wabj7R6b5PNVdYOZRxrCWvtdK8zm9+okd6iqA5PcOcmrZp5nFlX14ap6RVVdZvH4nVV1+Iq3vTLJ78ww3mqrTGfWrbRPkrNWeZZRnJxpK+JKt8nmT5TY2Vkfy52U6ZIyK90m03Ui14ujM91n+UqZToL4QFXdvqoOXFwf8YDF75r1aM38rnVW5sy6+4uLs81el+Q73f3puWeayfGZrlV17uLxryV5YVXddHGhyGT6h8Q+M823w1XV8xYPO8nTq2rp3R92TXKzrN+D/49N8ryqeuDi+VWq6taZrvn2pNmmmo/1sdyLk/yvxTFEmy6HcGima/+tp7N2983iQuXd/bTFsVTvWbz2W5l+z1wr6+9yKmvqd60wG8Orkzw3ybo9e6i7H7bk6cOSpKqen+S9VXVQkr9P8tAkH5thvNWyabdDJblOknOWvHZOks8medZqDzWC7n7G4npEH0iyZ5IPZ9q1+6zufuGsw83A+liuu59dVZdN8rxMxw4l0/8zx3T3M+abbNV9NdPZut9Kku7+m6p6WZIDknwp0668vWabbn5r4ndtdW9ujwmrqar2zRQjL+7uU+aeZyRVda0kL0myMdOBzUd097fnnWrHqqpXJHnE4mrVLFFVe2X6xbNLpgtDrrtLZSxlfSy3uO/wplt0fWm9rY+qemiS23b3XeeeZURr5XetMAMAGISD/wEABiHMAAAGIcwGUVVHzT3DSKyP5ayP5ayP5ayP5ayP5ayP5UZfH8JsHEP/hzID62M562M562M562M562M562O5odeHMAMAGMS6Pytz99qj98zec4+Rc3N2dssec48xDOtjOetjOetjOetjOetjOetjuVHWx0/zo9O6+3Irl6/7C8zumb1zcB069xgAwDrywX7rf2xuuV2ZAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAINY82FWVbvNPQMAwPYwXJhV1R2q6mNV9aOq+mFVva+qrrN47apV1VV1z6r6UFWdmeRPFq/dv6pOqKqzquqrVfWoqhru+wMA2JINcw+wGXsneW6Sf09yiSR/meRdVXXdJe95epLHJPnjJOdW1ZFJnpzkYUk+k+T6SV6S5NwkL1i90QEALrrhwqy737b0eVXdP8npSW6W5DuLxc/v7rcuec8TkjxuybJvVtX/THJ0NhNmVXVUkqOSZM/std2/BwCAi2K4MKuqayR5SpKDk1wu0+7WXZIcmAvD7Lgl779ckqskeXFV/e8lX2pDktrc39HdxyY5NkkuWfv2dv4WAAAukuHCLMk/ZgqwP0ny3STnJTkhye5L3vOzJY83HUf2oCT/shoDAgDsCEOFWVXtl+TaSY7u7g8vlt0kv2TO7v5eVZ2c5Brd/erVmRQAYPsbKsyS/CjJaUmOrKpvJ7lSkmdm2mr2yzwxyfOr6sdJ/inJbklukuRK3f30HTgvAMB2M9TlJLr7giT3SHLDJMcneWGSJyQ5+1d83kuTPCDJfZN8PsnHMh3c/80dOS8AwPY02hazdPeHMl3uYql9ljze0gH9b0jyhh01FwDAjjbUFjMAgPVMmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADGLD3APMraqyy557zj3GMOrAK809wlC+/pS95x5hKLsev8/cIwzloOd+Ye4RxnLBBXNPMJQLfv7zuUdgZL35xbaYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxCmAEADEKYAQAMQpgBAAxi9jCrqvtV1Q+qao8Vy19XVe9cPP6Tqjqxqs5Z/Hnkivd2Vd1txbJvVdVjdvx3AACwfcweZknekmmO/7ppQVVdKsmdk7ysqu6c5AVJnpvk+kmOSfJ3VfWHM8wKALDDbJh7gO4+s6pel+QBSd68WHyvJKcneXeS/5PkNd39gsVrX62qmyb50yTvuih/Z1UdleSoJNmz9r4Y0wMAbD8jbDFLkpckuV1VXXnx/AFJXtXd5yW5TpJPrHj/x5Nc96L+Zd19bHdv7O6Nu2ePX/0JAACrYIgw6+7PJ/lskiOq6vpJNiZ5+a/6tBWPa8Xru22/CQEAdrwhwmzhJUmOSPLAJJ/o7q8sln8pya1WvPe3k5yw5Pn3kxyw6UlV7b/0OQDAWjD7MWZLvCHJc5I8OMmDlix/ZpK3VNVnkrw/yR2S3DvJXZa850NJHlJV/5Lk/CRPS3LWagwNALC9DLPFrLt/mung/7Nz4UkA6e5/SPKwJI/KtJXsEUmO7u6lB/7/jyTfSPKRJG9N8tIkp67K4AAA28lIW8ySaffjm7r7Z0sXdveLkrxoS5/U3ScnueOKxW/b/uMBAOw4Q4RZVV0mya2T3D7JjWYeBwBgFkOEWZJ/S7Jvkj/v7uPnHgYAYA5DhFl3X3XuGQAA5jbMwf8AAOudMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGMSGuQeYW6fT55039xjDuOBr35h7hKFc8eU3nXuEofz4GnNPMJavPO26c48wlKu/7dy5RxjKhk9+ce4RhtLnnDP3CGuCLWYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAgxBmAACDEGYAAIMQZgAAg1izYVZVH6mqF2ztcwCA0W2Ye4BfpaqOSPKC7t5nxUt3SXLu6k8EALBjDB9mW9LdP5x7BgCA7WmYXZlVdZuq+lRVnVFVP6mqT1fVQ5O8IsneVdWLjyct3m9XJQCwUxlii1lVbUjyjiQvS3LvJLsluUmSLyZ5ZJKnJbnG4u1nzDEjAMCONkSYJblkkksneVd3f32x7MtJUlW/maS7+5Tt9ZdV1VFJjkqSPbPX9vqyAAAXyxC7MhfHi70yyfuq6t1V9eiqOnAH/n3HdvfG7t64W+2xo/4aAIBtMkSYJUl33z/JwUk+muROSb5SVYfNOxUAwOoZJsySpLs/391/292HJPlIksOTnJNk1znnAgBYDUOEWVVdrar+Z1XdsqoOqqrbJrlhkhOSfCvJnlV1u6q6bFU5KAwA2CmNcvD/z5NcK8lbklw2yfeSvC7J33b3uVX1oiRvSLJfkr9O8qSZ5gQA2GGGCLPu/l6mK/lv6fUHJ3nwimWHbMtzAIDRDbErEwAAYQYAMAxhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMIgNcw8wu076/PPnnmIc3XNPMJTd33fc3CMMZf8NfmQsddaf32zuEYZy3Wd9du4RhvL1u15h7hGGct63T557hDXBFjMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBB7HRhVlVXraquqo1zzwIAsC12ujADAFir1mSYVdUdqupjVfWjqvphVb2vqq6zePmbiz//dbHl7CMzjQkAsE3WZJgl2TvJc5PcLMkhSX6S5F1VtftiWZLcIckBSe4yx4AAANtqw9wDXBTd/balz6vq/klOzxRl31ks/kF3n7K5z6+qo5IclSR7Zq8dOCkAwNZbk1vMquoaVfX6qvp6VZ2e5HuZvpcDt+bzu/vY7t7Y3Rt3yx47dFYAgK21JreYJfnHTFvG/iTJd5Ocl+SEJLvPORQAwMWx5sKsqvZLcu0kR3f3hxfLbpILv5dzFn/uOsN4AAAX2ZoLsyQ/SnJakiOr6ttJrpTkmZm2miXJqUnOTHJYVX0ryVnd/ZM5BgUA2BZr7hiz7r4gyT2S3DDJ8UlemOQJSc5evH5ekocneWCSk5O8Y55JAQC2zVrcYpbu/lCS669YvM+S11+a5KWrOhQAwMW05raYAQDsrIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAgNsw9wBC6554A1oQ+77y5RxjKQU8/bu4RhnLiW6469whDOfidX5x7hKG8/WWHzD3CWI5502YX22IGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMIjtGmZV9ZGqesH2/JoAAOuFLWYAAIMQZgAAg9gRYbZLVT2tqk6rqlOr6llVtUuSVNVlqupVVfWjqjqzqj5YVdfb9IlVdURVnVFVd6yqL1fVz6vqnVV1qaq6W1V9rap+UlWvqapLLPm8qqrHVdXXF1/3C1V1nx3wvQEA7DA7IszuneS8JLdM8tAkj0xyj8Vrr0xycJL/muRmSX6e5L1LIyvJHkn+x+LrHJpkY5K3JTk8yV2T/Lckf5Dk6CWf8zdJ/jjJQ5JcN8nTk7y4qn5/cwNW1VFVdVxVHXduzr6Y3y4AwPaxYQd8zRO6+68Wj79aVUcmObSqjktypyT/pbs/miRVdd8kJ2WKsJcumekh3f2VxXten+RRSfbv7tMWy96R5LZJnl1Veyd5dJLbd/fHFl/jm1V1s0yh9u6VA3b3sUmOTZJL1r69Xb97AICLaEeE2b+veH5ykssnuU6SC5J8ctML3f2TqvpCpq1cm5y9KcoWvpfklE1RtmTZps+5bpI9M215WxpZuyX51sX4PgAAVtWOCLNzVzzv/OpdpkuD6rzNvPbLvuamP/8w09a3XzYLAMCwdkSYbcmXMkXULZJs2pV5ySQ3SPKKi/F1T0hydpKDuvtDF3dIAIC5rFqYdffXFseGvbiqjkry4yRPTXJ6ktdfjK/706p6VpJnVVVlir59ktw8yQWL48kAAOA7RJ4AAAnBSURBVIa32tcxu3+STyd55+LPvZLcobvPvJhf9wlJnpTkMUm+mOQDmc7g/ObF/LoAAKumutf3SYmXrH374Dp07jGANah2233uEYayyzUPmnuEoRz8xi/OPcJQ3v6yQ+YeYShfOObRn+nujSuXu/I/AMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCA2zD0AwFrV554z9whDOf/LJ849wlA+/Ge3mnuEoXzuZX839whD2fWYzS+3xQwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQwgwAYBDCDABgEMIMAGAQO1WYVdVDq+rfqupnVfXtqnr83DMBAGytDXMPsJ0dmuSvknwxyW2SvLSqvtjd75x3LACAX22nCrPuvvOSp9+oqqclueZc8wAAbIudKsyWqqo/T7Jbkjdu5rWjkhyVJHtmr1WeDABg83aqY8w2qaq/TPLIJLfr7pNXvt7dx3b3xu7euFv2WP0BAQA2Y6fbYlZVV0zy5CS/392fm3seAICttTNuMTsgSSX50tyDAABsi50xzL6U5LeS/MIuTACAke2MYXb9JK9Ncrm5BwEA2BY7Y5jtleQ3Mp2RCQCwZux0B/9390cyHWMGALCm7IxbzAAA1iRhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwiA1zDwDAzqE27Db3CEPZ+9+/O/cIQ7nNF+489wiDeeZml9piBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADAIYQYAMAhhBgAwCGEGADCINRNmVfWYqvrW3HMAAOwoaybMAAB2dtslzKrqklV16e3xtbbh77xcVe25mn8nAMCOdJHDrKp2rarDqur1SU5JcqPF8ktV1bFVdWpV/bSq/k9VbVzyeUdU1RlVdWhVHV9VP6uqD1fV1VZ8/cdV1SmL9746yT4rRvi9JKcs/q5bXdTvAwBgFNscZlV1vap6RpJvJ3lTkp8luUOSj1ZVJXl3kisl+YMkv5nko0k+VFUHLPkyeyR5fJIHJLlFkksnedGSv+PuSf4myROT3CTJV5I8esUor0tyryS/luQDVXViVf3VysDbwvdwVFUdV1XHnZuzt3UVAADsEFsVZlW1X1U9vKo+k+Tfklw7ySOSXKG7j+zuj3Z3J7ltkhsnuVt3f7q7T+zuJyT5RpL7LvmSG5I8ZPGef0/yrCSHLMIuSR6Z5FXd/eLu/mp3PzXJp5fO1N3ndfc/dfc9k1whydMWf//XquojVfWAqlq5lW3T5x7b3Ru7e+Nu2WNrVgEAwA63tVvMHpbkmCRnJblWd9+pu9/S3WeteN9Nk+yV5PuLXZBnVNUZSa6f5BpL3nd2d39lyfOTk+ye5DKL59dJ8skVX3vl8/+vu0/v7pd3922T/FaS/ZO8LMndtvL7AwCY3YatfN+xSc5Ncr8kx1fV25O8Jsk/d/f5S963S5LvJbn1Zr7G6Usen7fitV7y+dusqvbItOv0PpmOPftipq1u77goXw8AYA5bFULdfXJ3P7W7fyPJ7yY5I8kbk3ynqp5dVTdevPWzmbZWXbDYjbn049RtmOtLSW6+Ytmy5zX57ap6caaTD56f5MQkN+3um3T3Md39o234OwEAZrXNW6i6+1Pd/eAkB2TaxXmtJP9aVbdO8sEkn0jyjqq6Y1VdrapuUVV/vXh9ax2T5PCqOrKqfr2qHp/k4BXvuU+S9ye5ZJJ7JrlKdz+2u4/f1u8JAGAEW7sr8xd099lJ3prkrVV1+STnd3dX1e9lOqPyJUkun2nX5ieSvHobvvabqurqSZ6a6Zi1dyZ5TpIjlrztnzOdfHD6L34FAIC1p6aTKdevS9a+fXAdOvcYAGte7bb73CMMZdfLX3buEYby05e7CsJSn7j9Mz/T3RtXLndLJgCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEEIMwCAQQgzAIBBbJh7AAB2Dn3uOXOPMJTzvnvy3CMM5RKHzT3B2mCLGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCCEGQDAIIQZAMAghBkAwCA2zD3AHKrqqCRHJcme2WvmaQAAJutyi1l3H9vdG7t7427ZY+5xAACSrNMwAwAYkTADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABiEMAMAGIQwAwAYhDADABhEdffcM8yqqr6f5D/mniPJZZOcNvcQA7E+lrM+lrM+lrM+lrM+lrM+lhtlfRzU3ZdbuXDdh9koquq47t449xyjsD6Wsz6Wsz6Wsz6Wsz6Wsz6WG3192JUJADAIYQYAMAhhNo5j5x5gMNbHctbHctbHctbHctbHctbHckOvD8eYAQAMwhYzAIBBCDMAgEEIMwCAQQgzAIBBCDMAgEH8Pz90va/fWDJvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjPC6ADsXG0V",
        "colab_type": "code",
        "outputId": "36c85554-f710-4d0e-b584-2da4ef19bd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        }
      },
      "source": [
        "# wrong translation\n",
        "translate(u'trata de averiguarlo.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> trata de averiguarlo . <end>\n",
            "Predicted translation: try to find up . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeZXZa3iWN-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# got the file 'fra.txt' from here http://www.manythings.org/anki/fra-eng.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui85dYlUYUOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1Je1-iEWDq8qPl2ye1PwcNlv1Yw-F73sp'\n",
        "\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "downloaded.GetContentFile('fra.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klUw63tfYUSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 5  # Number of epochs to train for. useed just 5\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = 'fra.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4NXBQeak5n9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m56NPlxQk5qo",
        "colab_type": "code",
        "outputId": "f76f1917-a1ee-47c7-84e4-eb243161410f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 71\n",
            "Number of unique output tokens: 93\n",
            "Max sequence length for inputs: 16\n",
            "Max sequence length for outputs: 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxpWof_ik5tK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4d6dtuWk5v7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLOAADkXlAqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2adJMQkDlAtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QawvGNv2lAv0",
        "colab_type": "code",
        "outputId": "83a9eac5-a3a1-45e3-adfc-a647e74a4210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/5\n",
            "8000/8000 [==============================] - 26s 3ms/step - loss: 1.2002 - accuracy: 0.7233 - val_loss: 1.1999 - val_accuracy: 0.6994\n",
            "Epoch 2/5\n",
            "8000/8000 [==============================] - 25s 3ms/step - loss: 0.8538 - accuracy: 0.7690 - val_loss: 0.9239 - val_accuracy: 0.7416\n",
            "Epoch 3/5\n",
            "8000/8000 [==============================] - 24s 3ms/step - loss: 0.7049 - accuracy: 0.8012 - val_loss: 0.7226 - val_accuracy: 0.7908\n",
            "Epoch 4/5\n",
            "8000/8000 [==============================] - 24s 3ms/step - loss: 0.6037 - accuracy: 0.8255 - val_loss: 0.6629 - val_accuracy: 0.8066\n",
            "Epoch 5/5\n",
            "8000/8000 [==============================] - 24s 3ms/step - loss: 0.5511 - accuracy: 0.8392 - val_loss: 0.6252 - val_accuracy: 0.8163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H8qEryMk5yV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ4Gr6rflVHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNxJQnE6lVJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3tqTvdSlYMH",
        "colab_type": "code",
        "outputId": "45fad2e3-2866-4d53-9a09-8475fc2ae388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Est-ce le tous ?\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Est-ce le tous ?\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: Elles ant coune.\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Laissez l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Laisez la coure.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Laisez la coure.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Laisez la coure.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I won.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: Est-ce le tous ?\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Attez la chait !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Attez la chait !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Attez la chait !\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Attez la chait !\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Artez de le coure.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Artez de le coure.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Artez de le coure.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Hug me.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: Je suis pas parti.\n",
            "\n",
            "-\n",
            "Input sentence: I fell.\n",
            "Decoded sentence: Je suis pas parti.\n",
            "\n",
            "-\n",
            "Input sentence: I know.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I left.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I left.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I lied.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I lost.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I paid.\n",
            "Decoded sentence: Je suis pas parte.\n",
            "\n",
            "-\n",
            "Input sentence: I'm 19.\n",
            "Decoded sentence: Je suis pas parti.\n",
            "\n",
            "-\n",
            "Input sentence: I'm OK.\n",
            "Decoded sentence: Je suis pas parti.\n",
            "\n",
            "-\n",
            "Input sentence: I'm OK.\n",
            "Decoded sentence: Je suis pas parti.\n",
            "\n",
            "-\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: No way!\n",
            "Decoded sentence: Attez le toit !\n",
            "\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Really?\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Thanks.\n",
            "Decoded sentence: Elle l'ait de lait.\n",
            "\n",
            "-\n",
            "Input sentence: We try.\n",
            "Decoded sentence: Vous êtes doure.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Tome sont paste.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Tome sont paste.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Tome sont paste.\n",
            "\n",
            "-\n",
            "Input sentence: We won.\n",
            "Decoded sentence: Tome sont paste.\n",
            "\n",
            "-\n",
            "Input sentence: Ask Tom.\n",
            "Decoded sentence: Attez-le !\n",
            "\n",
            "-\n",
            "Input sentence: Awesome!\n",
            "Decoded sentence: Est-ce le tous ?\n",
            "\n",
            "-\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: Soyez pastent !\n",
            "\n",
            "-\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: Soyez pastent !\n",
            "\n",
            "-\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: Soyez pastent !\n",
            "\n",
            "-\n",
            "Input sentence: Be cool.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be kind.\n",
            "Decoded sentence: Soyez pastent !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: Soyez pastille !\n",
            "\n",
            "-\n",
            "Input sentence: Beat it.\n",
            "Decoded sentence: Sontez la chait !\n",
            "\n",
            "-\n",
            "Input sentence: Call me.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Call me.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Call us.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Call us.\n",
            "Decoded sentence: Artez de l'ait !\n",
            "\n",
            "-\n",
            "Input sentence: Come in.\n",
            "Decoded sentence: Sontez la chait !\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ821s-clYPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the end"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PndAmlL8lYSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AbYWg6LlVMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHqdHb2UlVPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLotCKlWlVRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5Oi6j1Fk500",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}